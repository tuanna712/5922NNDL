{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Coding Tutorial 13: Chain of Thought Prompting and Inference Playground\n",
        "\n",
        "```\n",
        "Course: CSCI 5922 Spring 2025, University of Colorado Boulder\n",
        "TA: Everley Tseng\n",
        "Email: Yu-Yun.Tseng@colorado.edu\n",
        "* AI assistant is used in making this tutorial\n",
        "```"
      ],
      "metadata": {
        "id": "rFcRJ2_Qn8yZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "Sections:\n",
        "- Chain-of-Thought Prompting\n",
        "- Hugging Face Inference Playground\n",
        "\n",
        "Objectives:\n",
        "- Learn the prompting methods for foundation models\n",
        "- Test prompting methods on the open-source models"
      ],
      "metadata": {
        "id": "rTJW3upooKFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain-of-Thought Prompting"
      ],
      "metadata": {
        "id": "JBXTaTKBpfA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chain-of-Thought (CoT) prompting** is a technique designed to help large language models (LLMs) like GPT-3 reason through complex tasks more effectively. Normally, when these models are given a question or problem, they provide an answer directly. However, for problems that require multiple steps to solve—like math problems or logical reasoning—this can lead to mistakes or incomplete answers.\n",
        "\n",
        "CoT prompting changes this approach by encouraging the model to explain its thought process **step by step** before reaching a final answer. This method works by giving the model the prompt to \"think aloud\" and break down the problem into smaller, easier-to-handle steps. By doing this, the model can better understand and solve tasks that require reasoning.\n",
        "\n",
        "CoT is especially helpful when using large models for **tasks they haven’t been explicitly trained on**. By providing intermediate steps, the model can solve unfamiliar problems in a more structured way, similar to how humans break down complex problems into simpler ones. Even though modern models have been trained on a wide variety of tasks, they can still benefit from Chain-of-Thought (CoT) prompting, especially for tasks that require multi-step reasoning or complex logic."
      ],
      "metadata": {
        "id": "b74OpEH4piGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test the effects of Chain-of-Thought prompting, you can use the Hugging Face Inference Playground to test the existing zero-shot foundation models. The following examples are good entries for chain-of-thought prompts. We encourage you to test these prompts on Hugging Face."
      ],
      "metadata": {
        "id": "Mp0erijFvUcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1"
      ],
      "metadata": {
        "id": "7fHwdtmRvmQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Zero-shot]**\n",
        "\n",
        "A rectangle has a length of 8 cm and a width of 5 cm. If the length is increased by 3 cm and the width is decreased by 1 cm, what is the area of the new rectangle?\n",
        "\n",
        "**[Few-shot]**\n",
        "\n",
        "Example: A rectangle has a length of 6 cm and a width of 4 cm. If the length is increased by 2 cm and the width is decreased by 1 cm, what is the area of the new rectangle? Answer: 24.\n",
        "\n",
        "Now, a rectangle has a length of 8 cm and a width of 5 cm. If the length is increased by 3 cm and the width is decreased by 1 cm, what is the area of the new rectangle?\n",
        "\n",
        "**[Chain-of-thought]**\n",
        "\n",
        "Example 1: A rectangle has a length of 6 cm and a width of 4 cm. If the length is increased by 2 cm and the width is decreased by 1 cm, what is the area of the new rectangle?\n",
        "\n",
        "Let's break this down step by step:\n",
        "\n",
        "The original rectangle has a length of 6 cm and a width of 4 cm. First, we need to adjust the length and width. The length is increased by 2 cm, so the new length is 6 cm + 2 cm = 8 cm. The width is decreased by 1 cm, so the new width is 4 cm - 1 cm = 3 cm. To find the area of the new rectangle, we multiply the length and width: 8 × 3 = 24. Therefore, the area of the new rectangle is 24. Answer: 24.\n",
        "\n",
        "Now, a rectangle has a length of 8 cm and a width of 5 cm. If the length is increased by 3 cm and the width is decreased by 1 cm, what is the area of the new rectangle?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FH7VrXxV-gml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2"
      ],
      "metadata": {
        "id": "FzoWuFPFAGkD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Zero-shot]**\n",
        "\n",
        "If John is older than Mary, and Mary is older than Sarah, who is the oldest person among the three?\n",
        "\n",
        "**[Few-shot]**\n",
        "\n",
        "Example: If Alice is taller than Bob, and Bob is taller than Charlie, who is the tallest among the three? Answer: Alice.\n",
        "\n",
        "Now, if John is older than Mary, and Mary is older than Sarah, who is the oldest person among the three?\n",
        "\n",
        "**[Chain-of-thought]**\n",
        "\n",
        "Example: If Alice is taller than Bob, and Bob is taller than Charlie, who is the tallest among the three?\n",
        "\n",
        "Let's think about this logically, step by step:\n",
        "\n",
        "We are given that Alice is taller than Bob. We are then given Bob is taller than Charlie. If Alice is taller than Bob and Bob is taller than Charlie, Alice is taller than Charlie. So, Alice is taller than both Bob and Charlie. Therefore, Alice is the oldest person because Alice is taller than Bob and Charlie. Answer: Alice.\n",
        "\n",
        "Now, if John is older than Mary, and Mary is older than Sarah, who is the oldest person among the three?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MNGsXm5PvmNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face Inference Playground"
      ],
      "metadata": {
        "id": "BR7ksCxM011M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Hugging Face Inference Playground is an interactive tool that allows you to easily test and experiment with pre-trained models, including foundation models. It is designed for users who want to explore cutting-edge machine learning models without the need to set up complex code or infrastructure. Foundation models often require substantial storage space and computational power, so using this interface to test them is a convenient way to access these powerful models without the overhead.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G-y7EfPB__gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Follow these steps to access the interface:\n",
        "1. Sign up for a an account on [Hugging Face](https://huggingface.co/)\n",
        "2. Go to account -> **Settings**\n",
        "3. In the sidebar, select **Access Tokens**\n",
        "4. Click on **Create new token**. Under the section **Inference**, select \"Make calls to inference providers\", \"Make calls to Inference Endpoints\", and \"Manage Inference Endpoints\". Click on \"Create token\".\n",
        "5. Copy the access token. Once this tab is closed, you won't have access to it.\n",
        "6. Go to the [Interface Playground](https://huggingface.co/playground). Select a model from the drop-down menu in the top-right corner.\n",
        "7. Enter message to interact with the model. When click on \"Run\", you'll need to input the access token.\n",
        "\n",
        "**Note**: The free token is limited, so be carefully with spending your quota!"
      ],
      "metadata": {
        "id": "o5fr366VHmE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discussion"
      ],
      "metadata": {
        "id": "QJQaE1WeKW2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What differences do you see in the model responses using the three prompts? Does the model analyze the problem is the instructed chain-of-thought method?"
      ],
      "metadata": {
        "id": "hWoW053UKoJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More Examples"
      ],
      "metadata": {
        "id": "2EHBNMIfvmCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you come up with your own example for foundation models to learn how to break down complex logic or math?"
      ],
      "metadata": {
        "id": "7-p1A3cwBplT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For any questions and discussions regarding this tutorial, attend [TA office hours](https://docs.google.com/spreadsheets/d/1fzfTJpEF7RaUYRA_NGa3DkiazdQXVj7QNBbp6DrEZ3I/edit?usp=sharing) or create a post on [Piazza](https://piazza.com/colorado/spring2025/csci5922/home) :) See you in the next tutorial!\n",
        "\n",
        "\\- Everley"
      ],
      "metadata": {
        "id": "VraiZwyhK-fM"
      }
    }
  ]
}